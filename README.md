# VHub

## Overview in English

The goal of this project is to apply pose estimation to a 3D avatar using [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/guide?hl=en).
All you need is an RGB camera that captures you. No depth camera or motion capture is needed.

The most advanced branch is "feature/MediaPipeDevelop" as of 8th November.

Docs are [here](https://github.com/Yupopyoi/VHub/tree/feature/MediaPipeDevelop/Reference/MediaPipe).  

## 日本語概要

このプロジェクトでは、[MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/guide?hl=ja)によるポーズ推定を、３Dアバターへリアルタイムに適用することを目標にします。  
必要なのは、RGBカメラのみです。デプスカメラやモーションキャプチャーは必要ありません。  

11月8日現在、最も進んでいるブランチは "feature/MediaPipeDevelop" です。  

製作における参考資料は [このディレクトリ](https://github.com/Yupopyoi/VHub/tree/feature/MediaPipeDevelop/Reference/MediaPipe) に格納してあります。

## Progress

![SampleGif](https://github.com/Yupopyoi/VHub/blob/feature/MediaPipeDevelop/Reference/Gif/LeftArmSample.gif)

I'm implementing the movement of the left arm...
I know that the movement is sometimes unnatural, and I will modify that in the future.
In addition, the slight delay is intentional.

## Environment

Unity 2022.3.42f1

## Contribution

This project uses [MediaPipeUnityPlugin](https://github.com/homuler/MediaPipeUnityPlugin) created by homuler.  
I would like to express my sincere gratitude to him.

## License

MIT License
